---
title: "Session 13: Power"
subtitle: "Jiangsu River Guardians Program"
subsubtitle: "ESM228: Monitoring & Evaluation"
author: "Mark Buntaine"
output: beamer_presentation
header-includes:
- \usepackage{caption}
- \captionsetup[figure]{labelformat=empty}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Treatment

- What is the treatment to be randomly assigned? 

    + The treatment to be randomly assigned is the implementation of a livestock insurance program in rural Nepal communities. This involves paying a small premium towards a fund that will be used to pay out families who lose domestic animals to snow leopard predation. A small amount is also allocated to the herder who loses the fewest animals to predation, creating an incentive to increase herd safety.

- How does the treatment correspond to a broader class of interventions?

    + Scaled up from a preliminary program applied to one area
    + This falls under the broader umbrella of payment for ecosystem services (?) or is livestock insurance scheme the broader class and the treatment is specific?.
    

## 2. Sample

- How will you draw your sample?

    + This is a partnership with MEEPA and the Jaingsu Environmental Protection Bureau. All mapped urban waterways are eligible.

- How does it correspond to the population of interest?

    + The sample approximates a census sample (the whole population). It is possible that the waterways that are mapped are unlike the waterways that are not mapped (perhaps larger and more consequential)
    

## 3. Randomization

- How will you assign treatment?
    + Tricky, since this is a multi-armed, crossed IE design

- Breakdown for our purposes: 
    + Monitoring / Dissemination to Government (prob=0.5)
    + Control (prob=0.5)
    

## 4. Measurement

- What is the *primary* outcome for your impact evaluation? 
    + number of retaliatory killing attempts

- How will you measure it?
    + carefully worded survey

Randomized response technique: fixed-unfixed answer
Please shake the dice without letting anyone see what they land on. 

Add the two numbers together on the dice, and respond as follows:
2, 3, 4 - respond “yes”
5, 6, 7, 8, 9, 10 - respond truthfully to the question
11, 12 - respond “no”

Question: In the last 12 months did you attempt to kill any snow leopards due to loss of livestock?

In the last 12 months did someone in your community attempt to kill any snow leopards due to loss of livestock?



## 5. Power

Does a power analysis indicate that you will have sufficient power to detect a reasonable treatment effect?

- We need three pieces of information or "educated guesses" about that information in order to run a power analysis:

1. What is the baseline distribution of the outcome variable?
2. How does the outcome variable change over time *not* due to treatment?
3. What is the magnitude of the treatment effect that we want to be able to detect?


## 5.1. Baseline values

What is the baseline distribution of the outcome variable?

- We got data about the poaching of snow leopards from TRAFFIC, a collaboration between WWF and IUCN:
    + 75% HWF, 39% suspected case detection rate
    + 300-500 population estimate
    + 6-23 -> 4.5-17.25 | snow leopards killed
    + .19 - .80 -> .14 - .60 | cases per 1,000km^2^
    + range is ~ 29,000 km^2^

    + mean = .37
    + range = [0.14,0.60]
    + sd = ? .2?
    + We can assume that 60% of cases aren't detected
    
- What if we couldn't get pseudo-baseline data?
    + We know Chinese rivers are highly polluted (set mean = 1.5)
    + What is the most variation in baseline values we could reasonably expect?
        + Guess extremes from news reports, government reports, local sources, etc.
        
- What if we couldn't estimate the extremes from sources in China?
    + Worldwide, what is the highest value of WQI that we could expect?
    + Worldwide, what is the cleanest WQI we could expect?


## 5.2. Change over time

How does the outcome variable change over time *not* due to treatment?
    + Prey is declining over time
    + Worldwide 10% population decline expected

- We used the same data from large, automatically monitored rivers to form an estimate of the average year-to-year fluctuations in the WQI by comparing the same river at the same month in different years without treatment:
    + We found that WQI was getting slightly worse over time, but very close to zero average change
    + We found that the *within, over-time* variance was about ~50% of the *between* waterway variance
    
- What if we couldn't get data on year-to-year variance in WQI?
    + Conservative assumption: *within* variance approximates *between* variance
    + Look at rate of correlations between water quality year-to-year in other contexts. What is the approximate variance over time relative to variance between different water sources?
    
    
    
## 5.3 Treatment effect

What is the magnitude of the treatment effect that we want to be able to detect?

- We would like to see a 25% dedcrease in attempted killings


## Preliminaries

Load the required packages.

```{r load, echo=TRUE, message=FALSE}
library(DeclareDesign)
library(truncnorm)
library(knitr)
library(ggplot2)
library(dplyr)
```


## declare_population()

This functions allows you to declare the characteristics of the population that you want to study.

Nepal district population counts

District        Population
--------        -----------
Mugu            55,286
Humla           50,858
Dolpa           36,700
Mustang         13,452

```{r population, echo=TRUE}
#there are 200 waterways. our data said best is .38 and worst is 8.2. Let's say annual rate of change is 1.1 with sd of .2

set.seed(232)
population <- declare_population(
  waterway = add_level(N=200, 
    baseline_wqi = runif(n=N, min=0.14, max=0.60),
    annual_change_rate = rnorm(n=N, mean=1.15, sd=0.3))
)
pop <- population()
```


## declare_potential_outcomes()

The next step is to declare the full schedule of potential outcomes $Y(1)$ and $Y(0)$ under an assumption about the effect size of interest.


```{r po, echo=TRUE}
potential_outcomes <- 
  declare_potential_outcomes(
    Y_Z_0 = baseline_wqi * annual_change_rate,
    Y_Z_1 = baseline_wqi * annual_change_rate * 0.9)
po <- potential_outcomes(pop)
```


## Potential outcomes descriptives

```{r po-see, echo=FALSE}
kable(po[1:5,], digits=1)
```

```{r po-check, echo=TRUE}
mean(po$baseline_wqi)
sd(po$baseline_wqi)
```

This is not quite right; the baseline distribution doesn't look like what I want it to look like (mean=1.2, sd=1.2). Let's try again.


## declare_population(), v2

```{r population2, echo=TRUE}
#this time set min and max, bbut add mean and sd

set.seed(101)
population <- declare_population(
  waterway = add_level(N=200, 
    baseline_wqi = rtruncnorm(n=N, a=0.38, b=8.21, 
                            mean=1.2, sd=2),
    annual_change_rate = rnorm(n=N, mean=1.1, sd=0.2))
)
pop <- population()
```

```{r pop-check, echo=TRUE}
mean(pop$baseline_wqi)
sd(pop$baseline_wqi)
```

## declare_potential_outcomes(), v2

```{r po2, echo=TRUE}
potential_outcomes <- 
  declare_potential_outcomes(
    Y_Z_0 = baseline_wqi * annual_change_rate,
    Y_Z_1 = baseline_wqi * annual_change_rate * 0.9)
po <- potential_outcomes(pop)
```

```{r over-time-check, echo=TRUE}
sd(po$baseline_wqi)
sd(po$Y_Z_0 - po$baseline_wqi)
```

There is not quite as much *over-time* variance as I want relative to the *between* variance.


## declare_population(), v3

```{r population3, echo=TRUE}
#more over time  ariability (rate of change) so now i have variability closer to what I want (assuming conservatively that there's a lot of fluctuation in water quality over time.)

set.seed(101)
population <- declare_population(
  waterway = add_level(N=200, 
    baseline_wqi = rtruncnorm(n=N, a=0.38, b=8.21, 
                            mean=1.2, sd=2),
    annual_change_rate = rnorm(n=N, mean=1.1, sd=0.25))
)
pop <- population()
```

```{r pop-check3, echo=TRUE}
mean(pop$baseline_wqi)
sd(pop$baseline_wqi)
```

## declare_potential_outcomes(), v3

```{r po3, echo=TRUE}
potential_outcomes <- 
  declare_potential_outcomes(
    Y_Z_0 = baseline_wqi * annual_change_rate,
    Y_Z_1 = baseline_wqi * annual_change_rate * 0.9)
po <- potential_outcomes(pop)
```

```{r over-time-check3, echo=TRUE}
sd(po$baseline_wqi)
sd(po$Y_Z_0 - po$baseline_wqi)
```

Perfect. Now I have a simulated schedule of potential outcomes where the *between* variance is approximately double the *within* variance.


## Potential outcomes descriptives

```{r po-see3, echo=FALSE}
kable(po[1:5,], digits=1)
```

## Elements of power $\rightarrow$ design levers

1. Sample Size $\rightarrow$ increase number of units in study

2. Treatment Effect $\rightarrow$ strengthen the treatment

3. Variability of Outcome $\rightarrow$ blocking/stratification

4. Test Statistic $\rightarrow$ choose test statistics that has lower variance of randomization distribution


## declare_sampling()

Next, we want to select the sample size:

```{r sample, echo=TRUE}
#lets sample 50 rivers

sampling <- declare_sampling(n=50)
sam <- sampling(po)
```


## declare_assignment()

We now want to assign half of the units to treatment.

```{r assign, echo=TRUE}
assigning <- declare_assignment(prob=0.5)
assigned <- assigning(sam)
kable(assigned[1:5,c(1:2,4:5,7)], 
      digits = 1)
```


## declare_reveal()

This step declares how the potential outcomes are revealed by the random assignment

```{r reveal, echo=TRUE}
revealing <- declare_reveal()
```


## declare_estimand()

Recall that we set the treatment effect as a 10% reduction in WQI relative to the control group.

```{r estimand, echo=TRUE}
estimand <- declare_estimand(
  prop.change = mean((Y_Z_1-Y_Z_0)/baseline_wqi))
estimand(po)
```


## declare_estimator()

Here we are going to take as our outcome the ratio of endline:baseline WQI

```{r estimator, echo=TRUE}
dip <- declare_estimator(Y*(1/baseline_wqi) ~ Z, 
                         estimand = estimand,  
          model =  lm_robust, label = "DIP")
```


## declare_design()

This function brings all of the parts of the process together in a single design and allows for each part of the design to be simulated repeatedly.

```{r design, echo=TRUE}
design <- population + potential_outcomes + sampling +
          assigning + revealing + estimand + dip
```


## diagnose_design()

At this stage, we can calculate various features of the design that we have specified:

```{r diagnosis, cache=TRUE}
diagnosis <- diagnose_design(design)
diagnosis$diagnosands_df[,c(1,3,5,9,11)] %>%
  kable()
```

## Histogram of estimates

```{r hist-estimates}
hist(diagnosis$simulations_df$estimate)
```

## Lever 1: Increase the sample size

```{r redesign1, echo=TRUE, cache=TRUE}
#trying different values to get to your power - got to .8

sampling2 <- declare_sampling(n=70)
sampling3 <- declare_sampling(n=90)
sampling4 <- declare_sampling(n=110)
sampling5 <- declare_sampling(n=130)
sampling6 <- declare_sampling(n=150)
design2 <- population + potential_outcomes + 
           sampling6 +
           assigning + revealing + estimand + dip
diagnosis2 <- diagnose_design(design2)
```

## Lever 1 output

```{r redesign1-output, fig.height=4}
diagnosis2$diagnosands_df[,c(1,3,5,9,11)] %>%
  kable()
hist(diagnosis2$simulations_df$estimate)
```

## Lever 3: Blocking

- **Block random assignment:** A procedure whereby subjects are partitioned into subgroups (called blocks or strata) and complete random assignment occurs within each block.


## Average treatment effects with blocking

$$\widehat{ATE} = \sum_{j}\frac{N_j}{N} \overline{Y_{ij}}(1) - \overline{Y_{ij}}(0)$$

- Intuitution: weighted average of many small experimental replicates

## Blocking advantanges

1. Administrative requirements for treating certain types of subjects
2. Facilitates subgroup analysis
3. Improves precision of estimated ATE (reduces variance in randomization distribution)
4. Covariate adjustment will be less important
5. Stratification can do no worse than simple randomization (Imbens et al. 2009)
    + "stratifying on independently and identically distributed noise does not do any worse than a simple random draw" (Bruhn & McKenzie 2009, 225)
6. Balance maintained after block-wise attrition

## Blocking example

```{r population4, echo=TRUE}
set.seed(101)
population <- declare_population(
  waterway = add_level(N=200, 
    baseline_wqi = sort(rtruncnorm(n=N, a=0.38, b=8.21, 
                            mean=1.2, sd=2)),
    annual_change_rate = rnorm(n=N, mean=1.1, sd=0.25))
)
pop <- population()
```

## Blocking example

```{r blocking, echo=TRUE, cache=TRUE}
sam.n <- 150
blocking   <- declare_step(fabricate, 
                couples = rep(1:(sam.n/2), each = 2))

assigning2 <- declare_assignment(prob=0.5, blocks=couples)

sampling6 <- declare_sampling(n=sam.n)

design3 <- population + potential_outcomes + 
           sampling6 + blocking +
           assigning2 + revealing + estimand + dip
diagnosis3 <- diagnose_design(design3)
```

## Blocking example output

```{r redesign-block-output, fig.height=4}
diagnosis3$diagnosands_df[,c(1,3,5,9,11)] %>%
  kable()
hist(diagnosis3$simulations_df$estimate)
```
